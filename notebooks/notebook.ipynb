{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deephive.environment.utils import parse_config\n",
    "from datetime import datetime\n",
    "import os \n",
    "import numpy as np\n",
    "import neptune\n",
    "import torch\n",
    "from plot_utils import *\n",
    "from deephive.environment.optimization_environment import OptimizationEnv\n",
    "from deephive.environment.optimization_functions.benchmark_functions import FunctionSelector\n",
    "from deephive.environment.utils import mean_confidence_interval\n",
    "import pandas as pd\n",
    "function_selector = FunctionSelector()\n",
    "from deephive.policies.mappo import MAPPO\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "from dotenv import load_dotenv\n",
    "api_token = os.environ.get(\"NEPTUNE_API_TOKEN\")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEPHIVE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"../config/exp_config.json\"\n",
    "model_path = \"../models/pbest_unfreeze.pth\"\n",
    "model_path_2 = \"../models/gbest.pth\"\n",
    "config = parse_config(config_path)\n",
    "config['use_gbest'] = False\n",
    "config['use_lbest'] = False\n",
    "config[\"use_optimal_value\"] = True\n",
    "config[\"log_scale\"] = True\n",
    "config[\"include_gbest\"] = False\n",
    "config[\"negative\"] = True\n",
    "if config[\"include_gbest\"] or config[\"use_lbest\"]:\n",
    "    config[\"obs_dim\"] = 5\n",
    "else:\n",
    "    config[\"obs_dim\"] = 4\n",
    "config[\"ep_length\"] = 25\n",
    "\n",
    "config[\"min_action_std\"] = 0.001\n",
    "config[\"action_std\"] = 0.2\n",
    "config[\"variable_std\"] = False\n",
    "config[\"update_timestep\"] = 2\n",
    "config[\"decay_rate\"] = 0.99\n",
    "config[\"log_interval\"] = 500\n",
    "config[\"decay_interval\"] = 5\n",
    "config[\"save_interval\"] = 200\n",
    "config[\"test_decay_rate\"] = 0.9\n",
    "config[\"test_decay_start\"] = 0\n",
    "config[\"reward_scheme\"] = \"FullRewardScheme2\"\n",
    "config[\"observation_scheme\"]= \"SimpleObservationScheme\"\n",
    "config[\"n_episodes\"] = 5000\n",
    "config[\"plot_gif\"] = True\n",
    "config[\"plot_gbest\"] = True\n",
    "config[\"test_ep_length\"] = 100\n",
    "config[\"n_agents\"] = 12\n",
    "config[\"n_dim\"] = 2\n",
    "config['objective_function'] = \"BenchmarkFunctions\" \n",
    "config[\"function_id\"] = \"f01\"\n",
    "config[\"neighborhood_size\"] = 4\n",
    "config[\"topology\"] = \"random\"\n",
    "\n",
    "mode = \"train\"\n",
    "\n",
    "def initialize(config, mode=\"train\", **kwargs):\n",
    "    env = OptimizationEnv(config)\n",
    "    agent_policy = MAPPO(config)\n",
    "    if mode == \"test\" or mode == \"benchmark\":\n",
    "        model_path = kwargs.get(\"model_path\", None)\n",
    "        if model_path is None:\n",
    "            raise ValueError(\"Model path must be provided for testing\")\n",
    "        # check if model path is a list of paths\n",
    "        if isinstance(model_path, list):\n",
    "            agent_policies = []\n",
    "            for path in model_path:\n",
    "                agent_policy = MAPPO(config)\n",
    "                agent_policy.load(path)\n",
    "                agent_policies.append(agent_policy)\n",
    "            return env, agent_policies\n",
    "        else:\n",
    "            agent_policy.load(model_path)\n",
    "            return env, agent_policy\n",
    "    else:\n",
    "        return env, agent_policy\n",
    "    \n",
    "\n",
    "def get_action(observation, agent_policy, env, observation_std=None, **kwargs):\n",
    "    # Ensure observation_info is a numpy array\n",
    "    \n",
    "    if not isinstance(observation, np.ndarray):\n",
    "        observation = np.array(observation)\n",
    "        assert observation.shape[0] == env.n_dim, \"Observation must have the same number of dimensions as the environment\"\n",
    "\n",
    "    # Initialize observation_std with zeros or use provided std, ensuring it matches the shape of observation\n",
    "    if observation_std is None:\n",
    "        observation_std = np.zeros_like(observation)\n",
    "    else:\n",
    "        observation_std = np.array(observation_std)\n",
    "\n",
    "    # Flatten the observation and std arrays\n",
    "    observation_flat = observation.reshape(env.n_dim * env.n_agents, -1)  # Flatten to 1D array\n",
    "    observation_std_flat = observation_std.reshape(-1)  # Flatten to 1D array\n",
    "    # Pass the entire flattened observation and std arrays to select_action\n",
    "    action_flat = agent_policy.select_action(observation_flat, observation_std_flat)\n",
    "\n",
    "    # Reshape the flattened action array back to the original (n_agents, n_dim) shape\n",
    "    actions = action_flat.reshape(env.n_dim, env.n_agents).T  # Reshape to (n_agents, n_dim\n",
    "\n",
    "    return actions  # Return the action\n",
    "\n",
    "\n",
    "def get_direct_action(obs, obs_std, agent_policy):\n",
    "    torch_obs = torch.FloatTensor(obs)\n",
    "    torch_obs_std = torch.FloatTensor(obs_std)\n",
    "    action = agent_policy.policy.act(torch_obs, torch_obs_std)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env, agent_policy = initialize(config, mode=\"train\", model_path=None)\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_logger(api_token, tags, config, mode=\"train\"):\n",
    "        run = neptune.init_run(\n",
    "        project=\"DMO-LAB/DeepHive-V2\",\n",
    "        # source files = all python files in the current directory,\n",
    "        source_files=[\"*.py\"],\n",
    "        api_token=api_token,\n",
    "        tags=[tags, mode, config[\"objective_function\"], str(config[\"layer_size\"])]\n",
    "        )\n",
    "        return run\n",
    "\n",
    "def train(env, agent_policy, config, title=\"experiment_1\", **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "        \n",
    "    save_path = kwargs.get(\"save_path\", \"training_results/\")\n",
    "    save_path = os.path.join(save_path, title)\n",
    "    # make directory if it does not exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    n_episodes = config[\"n_episodes\"]\n",
    "    average_returns = []  \n",
    "    timestep = 0    \n",
    "    for i in range(n_episodes):\n",
    "        #print(f\"Episode {i} started, timestep {timestep}\")\n",
    "        obs, obs_std = env.reset()\n",
    "        episode_return = np.zeros(env.n_agents)\n",
    "        for step in range(env.ep_length):\n",
    "            #print(f\"Episode {i}, step {step}, timestep {timestep}\")\n",
    "            actions = get_action(obs, agent_policy, env, obs_std)\n",
    "            obs, reward, done, info = env.step(actions)\n",
    "            for ag in range(env.n_agents):\n",
    "                agent_policy.buffer.rewards += [reward[ag]] * env.n_dim\n",
    "                agent_policy.buffer.is_terminals += [done[ag]] * env.n_dim\n",
    "            episode_return += reward\n",
    "            obs, obs_std = obs\n",
    "            timestep += 1\n",
    "            if step == env.ep_length - 1:\n",
    "                average_returns.append(np.mean(episode_return))\n",
    "                if neptune_logger is not None:\n",
    "                    neptune_logger[\"train/average_return\"].log(average_returns[-1])\n",
    "                running_average_rewards = np.mean(average_returns)\n",
    "                \n",
    "            if neptune_logger and i % config[\"log_interval\"] == 0:\n",
    "                neptune_logger[f\"Episode_{i}/gbest_values\"].log(env.gbest[-1])\n",
    "\n",
    "        if i % config[\"update_timestep\"] == 0 and timestep > 0:\n",
    "            #print(f\"Updating policy at episode {i}\")\n",
    "            agent_policy.update()\n",
    "        if i % config[\"log_interval\"] == 0 and timestep > 0:\n",
    "            print(f\"Episode {i} completed\")\n",
    "            print(f\"Average return: {running_average_rewards}\")\n",
    "            if env.n_dim == 2:\n",
    "                env.render(type=\"history\", file_path=f\"{save_path}/episode_{i}.gif\")  \n",
    "                if neptune_logger:\n",
    "                    neptune_logger[f\"train/gifs/{i}.gif\"].upload(f\"{save_path}/episode_{i}.gif\")\n",
    "        if i % config[\"decay_interval\"] == 0 and timestep > 0:\n",
    "            agent_policy.decay_action_std(config[\"decay_rate\"], min_action_std=config[\"min_action_std\"], debug=False)\n",
    "        if i % config[\"save_interval\"] == 0 and timestep > 0:\n",
    "            if average_returns[-1] > running_average_rewards:\n",
    "                print(f\"Saving model at episode {i} with average return {average_returns[-1]} and running average {running_average_rewards}\")\n",
    "                agent_policy.save(save_path, episode=i)\n",
    "        \n",
    "    return agent_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title = \"experiment_104\"\n",
    "# tags = \"training with 4 observation using pbest and log scale\"\n",
    "# neptune_logger = initialize_logger(api_token, title, config, mode=\"train\")\n",
    "# agent_policy = train(env, agent_policy, config, title=title, neptune_logger=neptune_logger)\n",
    "# neptune_logger.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEPHIVE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env, agent_policy, iters, decay_start=100, decay_rate=0.995, \n",
    "         min_action_std=0.001, max_action_std=0.5, \n",
    "         save_gif = False, save_path = \"test_results\", function_id=0, **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_gbest_vals = []\n",
    "    print(f\"Testing function {function_id} with {env.n_agents} agents and {env.n_dim} dimensions\")\n",
    "    for iter in range(iters):\n",
    "        gbest_vals = []\n",
    "        obs = env.reset()[0]\n",
    "        agent_policy.set_action_std(max_action_std)\n",
    "        current_action_std = agent_policy.action_std\n",
    "        for step in range(env.ep_length):\n",
    "            action = get_action(obs, agent_policy, env)\n",
    "            obs, _ , _ , _ = env.step(action)\n",
    "            obs = obs[0]\n",
    "            gbest_vals.append(env.gbest[-1])\n",
    "            if neptune_logger:\n",
    "                neptune_logger[f\"test/{function_id}/Episode_{iter}/gbest_values\"].log(env.gbest[-1])\n",
    "            if step >= decay_start:\n",
    "                # Decay the std uniformly from the max to the min std over the specified rate\n",
    "                current_action_std = max(min_action_std, current_action_std * decay_rate)\n",
    "                agent_policy.set_action_std(current_action_std)   \n",
    "        if env.n_dim == 2 and save_gif:\n",
    "            env.render(type=\"history\", file_path=f\"{save_path}/episode_{iter}.gif\") \n",
    "            if neptune_logger:\n",
    "                neptune_logger[f\"test/{function_id}/gifs/{iter}.gif\"].upload(f\"{save_path}/episode_{iter}.gif\")\n",
    "        all_gbest_vals.append(np.array(gbest_vals))\n",
    "        print(f\"Final gbest value: {env.gbest[-1]} at iteration {iter}\")\n",
    "    \n",
    "    np.save(f\"{save_path}/{function_id}_gbest_history.npy\", np.array(all_gbest_vals))\n",
    "    return all_gbest_vals\n",
    "\n",
    "def analyze_results(base_path, model_lists, model_path_list, successful_functions, function_selector, **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    # Define a multi-level column structure: each optimizer has the same sub-columns\n",
    "    columns = pd.MultiIndex.from_product([model_lists, \n",
    "                                          [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]],\n",
    "                                         names=['optimizer', 'metric'])\n",
    "    # Initialize an empty DataFrame with these columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for function_id in successful_functions:\n",
    "        row_data = {}\n",
    "        function_info = function_selector.get_function(function_id)\n",
    "        function_opt_val = function_info[\"global_min\"]\n",
    "        \n",
    "        # Loop through each optimizer\n",
    "        for optimizer, model_path in zip(model_lists, model_path_list):\n",
    "            data_path = model_path + f\"deephive/{function_id}/{function_id}_gbest_history.npy\"\n",
    "            try:\n",
    "                # Attempt to load the optimizer's result and compute metrics\n",
    "                gbest_values = np.load(data_path) * -1\n",
    "                mean_val, lower_val, upper_val = mean_confidence_interval(gbest_values)\n",
    "                error_val = abs(mean_val[-1] - function_opt_val)\n",
    "                row_data[(optimizer, 'mean')] = mean_val[-1]\n",
    "                row_data[(optimizer, 'lower')] = lower_val[-1]\n",
    "                row_data[(optimizer, 'upper')] = upper_val[-1]\n",
    "                row_data[(optimizer, 'optimum')] = function_opt_val\n",
    "                row_data[(optimizer, 'error')] = error_val\n",
    "                \n",
    "                # Additional logging or plotting can be added here as needed\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {optimizer} for function {function_id}: {e}\")\n",
    "                # Fill missing values if any error occurs\n",
    "                for metric in [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]:\n",
    "                    row_data[(optimizer, metric)] = np.nan\n",
    "        \n",
    "        # After collecting data for all optimizers, add the row to the DataFrame\n",
    "        #df = df.append(pd.Series(row_data, name=function_id))\n",
    "        df.loc[function_id] = row_data\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    df.to_csv(f\"{base_path}/results.csv\")\n",
    "    \n",
    "    # Log the DataFrame if Neptune logger is provided\n",
    "    if neptune_logger:\n",
    "        neptune_logger[\"test/results\"].upload(f\"{base_path}/results.csv\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "def run_test(function_ids, iters, save_dir, model_path, config, **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    successful_functions = []\n",
    "    for function_id in function_ids:\n",
    "        try:\n",
    "            config[\"function_id\"] = function_id\n",
    "            function_dim = function_selector.get_function(function_id)[\"dimension\"]\n",
    "            if config[\"n_dim\"] > function_dim:\n",
    "                print(f\"function {function_id} has {function_dim} dimensions, setting n_dim to {function_dim}\")\n",
    "                config[\"n_dim\"] = function_dim\n",
    "            env, agent_policy = initialize(config, mode=\"test\", model_path=model_path)\n",
    "            _ = env.reset()[0]\n",
    "            agent_policy.load(model_path)\n",
    "            save_path = f\"{save_dir}/{function_id}\"\n",
    "            try:\n",
    "                all_gbest_vals = test(env, agent_policy, iters, decay_start=0, decay_rate=0.9, \n",
    "                                min_action_std=0.0001, max_action_std=0.5, \n",
    "                                save_gif = False, save_path = save_path, function_id=function_id, neptune_logger=neptune_logger)\n",
    "                successful_functions.append(function_id)\n",
    "            except Exception as e:\n",
    "                print(f\"Function {function_id} failed with error {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Function {function_id} failed with error {e}\")\n",
    "        \n",
    "    #df = analyze_results(save_dir, successful_functions, function_selector, neptune_logger=neptune_logger)\n",
    "    if neptune_logger: \n",
    "        neptune_logger.stop()\n",
    "    return successful_functions, save_dir, env, agent_policy\n",
    "\n",
    "\n",
    "def run_test_deephive(function_ids, iters, save_dir, model_path, config, **kwargs):\n",
    "    dimension = config[\"n_dim\"]\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    successful_functions = []\n",
    "    for function_id in function_ids:\n",
    "        try:\n",
    "            config[\"function_id\"] = function_id\n",
    "            function_dim = function_selector.get_function(function_id)[\"dimension\"]\n",
    "            if config[\"n_dim\"] > function_dim:\n",
    "                print(f\"function {function_id} has {function_dim} dimensions, setting n_dim to {function_dim}\")\n",
    "                config[\"n_dim\"] = function_dim\n",
    "            else:\n",
    "                config[\"n_dim\"] = dimension\n",
    "            \n",
    "            \n",
    "            env, agent_policy = initialize(config, mode=\"test\", model_path=model_path)\n",
    "            _ = env.reset()[0]\n",
    "            agent_policy.load(model_path)\n",
    "            \n",
    "            try:\n",
    "                test_save_path = f\"{save_dir}/deephive/{function_id}\"\n",
    "                all_gbest_vals = test(env, agent_policy, iters, decay_start=10, decay_rate=0.9, \n",
    "                                min_action_std=0.0001, max_action_std=0.5, \n",
    "                                save_gif = False, save_path = test_save_path, function_id=function_id, neptune_logger=neptune_logger)\n",
    "                plot_individual_function_evaluation(all_gbest_vals, config[\"n_agents\"], f\"{test_save_path}/{function_id}_individual.png\", log_scale=config[\"log_scale\"])\n",
    "                num_function_evaluation(all_gbest_vals, config[\"n_agents\"], f\"{test_save_path}/{function_id}_num_evaluations.png\", log_scale=config[\"log_scale\"])\n",
    "                if neptune_logger:\n",
    "                    neptune_logger[f\"deephive/{function_id}/individual\"].upload(f\"{test_save_path}/{function_id}_individual.png\")\n",
    "                    neptune_logger[f\"deephive/{function_id}/num_evaluations\"].upload(f\"{test_save_path}/{function_id}_num_evaluations.png\")\n",
    "            except Exception as e:\n",
    "                print(f\"Function {function_id} failed with error {e}\")\n",
    "            successful_functions.append(function_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Function {function_id} failed with error {e}\")\n",
    "        \n",
    "    #df = analyze_results(save_dir, successful_functions, function_selector, neptune_logger=neptune_logger)\n",
    "    if neptune_logger: \n",
    "        neptune_logger.stop()\n",
    "    return successful_functions, save_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_ids = [\"f01\"]#, \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\"]\n",
    "config[\"n_agents\"] = 40\n",
    "config[\"n_dim\"] = 30\n",
    "config['objective_function'] = \"BenchmarkFunctions\"\n",
    "config[\"ep_length\"] = 100\n",
    "config[\"log_scale\"] = True\n",
    "config[\"use_lbest\"] = True\n",
    "config[\"obs_dim\"] = 5\n",
    "MODEL_PATH = \"training_results/experiment_103/policy-4800.pth\"\n",
    "config[\"neighborhood_size\"] = 10\n",
    "env, agent_policy = initialize(config, mode=\"test\", model_path=MODEL_PATH)\n",
    "iters = 1\n",
    "save_dir = f\"new_test_results/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}/\" \n",
    "title = \"experiment_103\"\n",
    "tags = \"testing with 40 agents and log scale\"\n",
    "# neptune_logger = None #initialize_logger(api_token, title, config, mode=\"test\")\n",
    "# successfull_functions, save_dir, env, policy = run_test(function_ids, iters, save_dir, MODEL_PATH, config, neptune_logger=neptune_logger)\n",
    "_ = env.reset()[0]\n",
    "env.compute_lbest()\n",
    "len(set(env.lbest_positions[:, 0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_experiments = [102, 103, 104]\n",
    "model_lists = [\"gbest\", \"lbest\", \"pbest\"]\n",
    "obs_dim = [4, 5, 4]\n",
    "function_ids = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\",\n",
    "                \"f20\", \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \"f31\", \"f32\", \"f33\", \"f34\", \"f35\", \"f36\", \"f37\", \"f38\", \"f39\", \"f40\",\n",
    "                \"f41\", \"f42\", \"f43\", \"f44\", \"f45\", \"f46\", \"f47\", \"f48\", \"f49\", \"f50\"]\n",
    "#function_ids = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "config[\"n_agents\"] = 40\n",
    "config[\"n_dim\"] = 30\n",
    "config['objective_function'] = \"BenchmarkFunctions\"\n",
    "config[\"ep_length\"] = 1000\n",
    "config[\"log_scale\"] = False\n",
    "iters = 10\n",
    "config[\"neighborhood_size\"] = 10\n",
    "\n",
    "base_save_dir = f\"new_test_results/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}/\" \n",
    "for i, model in enumerate(model_experiments):\n",
    "    config[\"n_dim\"] = 30\n",
    "    config[\"n_agents\"] = 40\n",
    "    config[\"obs_dim\"] = obs_dim[i]\n",
    "    if i==1:\n",
    "        config[\"use_lbest\"] = True\n",
    "    else:\n",
    "        config[\"use_lbest\"] = False\n",
    "    MODEL_PATH = f\"training_results/experiment_{model}/policy-4800.pth\"\n",
    "    # env, agent_policy = initialize(config, mode=\"test\", model_path=MODEL_PATH)\n",
    "    title = f\"experiment_{model}\"\n",
    "    save_dir = base_save_dir + f\"model{model}/\"\n",
    "    tags = f\"testing with 40 agents and log scale\"\n",
    "    neptune_logger = None#initialize_logger(api_token, title, config, mode=\"test\")\n",
    "    successful_functions, save_dir = run_test_deephive(function_ids, iters, save_dir, MODEL_PATH, config, neptune_logger=neptune_logger)\n",
    "    if neptune_logger:\n",
    "        neptune_logger.stop()\n",
    "    print(f\"Experiment {model} completed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dir =base_save_dir #f\"new_test_results/2024-03-06_22-07-01/\"\n",
    "model_paths = [save_dir + f\"model{model}/\" for model in [102, 103, 104]]\n",
    "model_lists = [\"gbest\", \"lbest\", \"pbest\"]\n",
    "df = analyze_results(save_dir, model_lists, model_paths, successful_functions, function_selector, neptune_logger=neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{save_dir}/results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO-BSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOBSA:\n",
    "    def __init__(self, fitness_function, dimension, swarm_size, inertia_weight, \n",
    "                 acc_coefficients, mix_rate, mutation_probability, neighborhood_size,\n",
    "                 lower_bound=-100, upper_bound=100, scale=False, apply_mutation=False):\n",
    "        self.scale_option = scale\n",
    "        self.num_evaluations = 0\n",
    "        self.lower_bound = lower_bound  \n",
    "        self.upper_bound = upper_bound\n",
    "        self.obj_function = fitness_function\n",
    "        self.dimension = dimension\n",
    "        self.apply_mutation = apply_mutation\n",
    "        self.swarm_size = swarm_size\n",
    "        self.inertia_weight = inertia_weight\n",
    "        self.acc_coefficients = acc_coefficients  # Tuple (c1, c2)\n",
    "        self.mix_rate = mix_rate\n",
    "        self.mutation_probability = mutation_probability\n",
    "        self.neighborhood_size = neighborhood_size\n",
    "        self.positions = np.random.uniform(low=lower_bound, high=upper_bound, size=(swarm_size, dimension))\n",
    "        if self.scale_option:\n",
    "            self.positions = self.scale(self.positions)\n",
    "        self.velocities = np.zeros((swarm_size, dimension))\n",
    "        self.fitness_values = self.fitness_function(self.positions)\n",
    "        self.pbest_positions = np.copy(self.positions)\n",
    "        self.pbest_values = np.copy(self.fitness_values)\n",
    "        self.gbest_position = self.pbest_positions[np.argmin(self.pbest_values)]\n",
    "        self.gbest_values = self.pbest_values.min()\n",
    "        self.gbest_history = []\n",
    "        self.gbest_history.append(self.gbest_values)\n",
    "        \n",
    "    def fitness_function(self, positions, no_tracking=False):\n",
    "        if not no_tracking:\n",
    "            self.num_evaluations += len(positions)\n",
    "        if self.scale_option:\n",
    "            positions = self.unscale(positions)\n",
    "        return self.obj_function(positions)\n",
    "        \n",
    "    def scale(self, positions):\n",
    "        return 2 * (positions - self.lower_bound) / (self.upper_bound - self.lower_bound) - 1\n",
    "    \n",
    "    def unscale(self, positions):\n",
    "        return ((positions + 1) / 2) * (self.upper_bound - self.lower_bound) + self.lower_bound\n",
    "    \n",
    "    def initialize_neighborhoods(self):\n",
    "        self.neighborhoods = []\n",
    "        for i in range(self.swarm_size):\n",
    "            neighborhood_indices = list(range(i - self.neighborhood_size, i)) + list(range(i + 1, i + 1 + self.neighborhood_size))\n",
    "            neighborhood_indices = [index % self.swarm_size for index in neighborhood_indices]\n",
    "            self.neighborhoods.append(neighborhood_indices)\n",
    "    \n",
    "    def compute_lbest(self):\n",
    "        self.lbest_positions = np.zeros((self.swarm_size, self.dimension))\n",
    "        for i in range(self.swarm_size):\n",
    "            neighborhood_fitnesses = self.fitness_values[self.neighborhoods[i]]\n",
    "            best_neighbor_idx = self.neighborhoods[i][np.argmin(neighborhood_fitnesses)]\n",
    "            self.lbest_positions[i] = self.positions[best_neighbor_idx]\n",
    "    \n",
    "    def update_velocity(self):\n",
    "        r1, r2 = np.random.rand(self.swarm_size, self.dimension), np.random.rand(self.swarm_size, self.dimension)\n",
    "        cognitive_component = self.acc_coefficients[0] * r1 * (self.pbest_positions - self.positions)\n",
    "        social_component = self.acc_coefficients[1] * r2 * (self.gbest_position - self.positions)\n",
    "        self.velocities = self.inertia_weight * self.velocities + cognitive_component + social_component\n",
    "    \n",
    "    def update_positions(self):\n",
    "        self.positions += self.velocities\n",
    "        if self.scale_option:\n",
    "            self.positions = np.clip(self.positions, -1, 1)  # Scaled bounds\n",
    "        else:\n",
    "            self.positions = np.clip(self.positions, self.lower_bound, self.upper_bound)\n",
    "    \n",
    "    def calculate_fitness(self):\n",
    "        self.fitness_values = self.fitness_function(self.positions)\n",
    "        self.update_pbest_and_gbest()\n",
    "        \n",
    "    def update_pbest_and_gbest(self):\n",
    "        better_mask = self.fitness_values < self.pbest_values\n",
    "        self.pbest_positions[better_mask] = self.positions[better_mask]\n",
    "        self.pbest_values[better_mask] = self.fitness_values[better_mask]\n",
    "        gbest_candidate_idx = np.argmin(self.pbest_values)\n",
    "        if self.pbest_values[gbest_candidate_idx] < self.gbest_values:\n",
    "            self.gbest_position = self.pbest_positions[gbest_candidate_idx]\n",
    "            self.gbest_values = self.pbest_values[gbest_candidate_idx]\n",
    "            \n",
    "    def mutate(self, positions, lbest_positions):\n",
    "        A = 2 * np.random.rand(self.swarm_size, self.dimension)\n",
    "        phi = np.random.rand(self.swarm_size, self.dimension)\n",
    "        return positions + A * (phi * lbest_positions - positions)\n",
    "    \n",
    "    def crossover(self, positions, trial_positions):\n",
    "        crossover_mask = np.random.rand(self.swarm_size, self.dimension) < self.mix_rate\n",
    "        return np.where(crossover_mask, trial_positions, positions)\n",
    "\n",
    "    def mutate_and_crossover(self):\n",
    "        for i in range(self.swarm_size):\n",
    "            if np.random.rand() < self.mutation_probability:\n",
    "                trial_positions = self.mutate(self.positions, self.lbest_positions[i])\n",
    "            else:\n",
    "                self.permute_lbest(i)\n",
    "                trial_positions = self.mutate(self.positions, self.lbest_positions[i])\n",
    "            new_positions = self.crossover(self.positions, trial_positions)\n",
    "            new_fitness = self.fitness_function(new_positions)\n",
    "            better_mask = new_fitness < self.fitness_values\n",
    "            self.positions[better_mask] = new_positions[better_mask]\n",
    "            self.fitness_values[better_mask] = new_fitness[better_mask]\n",
    "            self.update_pbest_and_gbest()\n",
    "            # if np.min(new_fitness) < self.fitness_function(self.gbest_position.reshape(1, -1)):\n",
    "            #     self.gbest_position = new_positions[np.argmin(new_fitness)]\n",
    "            \n",
    "    \n",
    "    def permute_lbest(self, particle_index):\n",
    "        neighbor_indices = self.neighborhoods[particle_index]\n",
    "        np.random.shuffle(neighbor_indices)\n",
    "        self.lbest_positions[particle_index] = self.positions[neighbor_indices[0]]\n",
    "    \n",
    "    def optimize(self, iterations):\n",
    "        self.initialize_neighborhoods()\n",
    "        for _ in range(iterations):\n",
    "            self.compute_lbest()\n",
    "            self.update_velocity()\n",
    "            self.update_positions()\n",
    "            self.calculate_fitness()\n",
    "            if self.apply_mutation:\n",
    "                self.mutate_and_crossover()\n",
    "            self.gbest_history.append(self.gbest_values)\n",
    "        return np.array(self.gbest_history)\n",
    "   \n",
    "function_id = \"f01\"\n",
    "function_info = function_selector.get_function(function_id)\n",
    "fitness_function = function_info[\"func\"]\n",
    "dimension = function_info[\"dimension\"]\n",
    "lower_bound = function_info[\"domain\"][0]\n",
    "upper_bound = function_info[\"domain\"][1]\n",
    "global_min = function_info[\"global_min\"] \n",
    "swarm_size = 40\n",
    "apply_mutation = True\n",
    "pso_bsa = PSOBSA(fitness_function=fitness_function,\n",
    "                dimension=dimension,\n",
    "                swarm_size=swarm_size,\n",
    "                inertia_weight=0.7,\n",
    "                acc_coefficients=(1.4, 1.4),\n",
    "                mix_rate=1,\n",
    "                mutation_probability=0.2,\n",
    "                neighborhood_size=10,\n",
    "                scale=False,\n",
    "                lower_bound=lower_bound,\n",
    "                upper_bound=upper_bound,\n",
    "                apply_mutation=apply_mutation)\n",
    "\n",
    "gbest_history = pso_bsa.optimize(iterations=100)\n",
    "print(gbest_history[-1])\n",
    "print(pso_bsa.num_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pso(function_id, iters, save_dir, ep_length, apply_mutation=False, swarm_size=40, **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    try:\n",
    "        save_dir = f\"{save_dir}/{function_id}\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        function_info = function_selector.get_function(function_id)\n",
    "        fitness_function = function_info[\"func\"]\n",
    "        dimension = kwargs.get(\"dimension\", function_info[\"dimension\"])\n",
    "        lower_bound = function_info[\"domain\"][0]\n",
    "        upper_bound = function_info[\"domain\"][1]\n",
    "        global_min = function_info[\"global_min\"]\n",
    "        all_gbest_vals = []\n",
    "        for iter in range(iters):\n",
    "            pso_bsa = PSOBSA(fitness_function=fitness_function,\n",
    "                dimension=dimension,\n",
    "                swarm_size=swarm_size,\n",
    "                inertia_weight=0.7,\n",
    "                acc_coefficients=(1.4, 1.4),\n",
    "                mix_rate=1,\n",
    "                mutation_probability=0.2,\n",
    "                neighborhood_size=10,\n",
    "                scale=False,\n",
    "                lower_bound=lower_bound,\n",
    "                upper_bound=upper_bound,\n",
    "                apply_mutation=apply_mutation)\n",
    "            gbest_history = pso_bsa.optimize(iterations=ep_length)\n",
    "            all_gbest_vals.append(gbest_history)\n",
    "        np.save(f\"{save_dir}/{function_id}_gbest_history.npy\", np.array(all_gbest_vals))\n",
    "        if neptune_logger:\n",
    "            neptune_logger[f\"pso/{function_id}/gbest_history\"].upload(f\"{save_dir}/{function_id}_gbest_history.npy\")\n",
    "    except Exception as e:\n",
    "        print(f\"Function {function_id} failed with error {e}\")\n",
    "    return np.array(all_gbest_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(function_ids, iters, save_dir, model_path, config, **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    successfull_functions = []\n",
    "    for function_id in function_ids:\n",
    "        try:\n",
    "            config[\"function_id\"] = function_id\n",
    "            function_dim = function_selector.get_function(function_id)[\"dimension\"]\n",
    "            if config[\"n_dim\"] > function_dim:\n",
    "                print(f\"function {function_id} has {function_dim} dimensions, setting n_dim to {function_dim}\")\n",
    "                config[\"n_dim\"] = function_dim\n",
    "            env, agent_policy = initialize(config, mode=\"test\", model_path=model_path)\n",
    "            _ = env.reset()[0]\n",
    "            agent_policy.load(model_path)\n",
    "            \n",
    "            try:\n",
    "                test_save_path = f\"{save_dir}/deephive/{function_id}\"\n",
    "                all_gbest_vals = test(env, agent_policy, iters, decay_start=0, decay_rate=0.9, \n",
    "                                min_action_std=0.0001, max_action_std=0.5, \n",
    "                                save_gif = False, save_path = test_save_path, function_id=function_id, neptune_logger=neptune_logger)\n",
    "                plot_individual_function_evaluation(all_gbest_vals, config[\"n_agents\"], f\"{test_save_path}/{function_id}_individual.png\", log_scale=config[\"log_scale\"])\n",
    "                num_function_evaluation(all_gbest_vals, config[\"n_agents\"], f\"{test_save_path}/{function_id}_num_evaluations.png\", log_scale=config[\"log_scale\"])\n",
    "                if neptune_logger:\n",
    "                    neptune_logger[f\"deephive/{function_id}/individual\"].upload(f\"{test_save_path}/{function_id}_individual.png\")\n",
    "                    neptune_logger[f\"deephive/{function_id}/num_evaluations\"].upload(f\"{test_save_path}/{function_id}_num_evaluations.png\")\n",
    "            except Exception as e:\n",
    "                print(f\"Function {function_id} failed with error {e}\")\n",
    "            try:\n",
    "                pso_save_path = f\"{save_dir}/pso/\"\n",
    "                apply_mutation = False\n",
    "                pso_gbest_history = run_pso(function_id=function_id, iters=iters, save_dir=pso_save_path, \n",
    "                                            ep_length=config[\"ep_length\"], apply_mutation=apply_mutation, \n",
    "                                            neptune_logger=neptune_logger, swarm_size=config[\"n_agents\"], dimension=config[\"n_dim\"])\n",
    "                print(f\"PSO gbest history: {pso_gbest_history.shape}\")\n",
    "                plot_individual_function_evaluation(pso_gbest_history, config[\"n_agents\"], f\"{pso_save_path}/{function_id}_individual.png\", log_scale=config[\"log_scale\"])\n",
    "                num_function_evaluation(pso_gbest_history, config[\"n_agents\"], f\"{pso_save_path}/{function_id}_num_evaluations.png\", log_scale=config[\"log_scale\"])\n",
    "                if neptune_logger:\n",
    "                    neptune_logger[f\"pso/{function_id}/individual\"].upload(f\"{pso_save_path}/{function_id}_individual.png\")\n",
    "                    neptune_logger[f\"pso/{function_id}/num_evaluations\"].upload(f\"{pso_save_path}/{function_id}_num_evaluations.png\")\n",
    "            except Exception as e:\n",
    "                import traceback; traceback.print_exc();\n",
    "                print(f\"Function {function_id} failed with error {e}\")\n",
    "            try:\n",
    "                psobsa_save_path = f\"{save_dir}/psobsa/\"\n",
    "                apply_mutation = True\n",
    "                psobsa_gbest_history = run_pso(function_id=function_id, iters=iters, save_dir=psobsa_save_path, ep_length=config[\"ep_length\"],\n",
    "                                               apply_mutation=apply_mutation, neptune_logger=neptune_logger, swarm_size=config[\"n_agents\"], dimension=config[\"n_dim\"])\n",
    "                print(f\"PSO-BSA gbest history: {psobsa_gbest_history.shape}\")\n",
    "                plot_individual_function_evaluation(psobsa_gbest_history, config[\"n_agents\"], f\"{psobsa_save_path}/{function_id}_individual.png\", log_scale=config[\"log_scale\"])\n",
    "                num_function_evaluation(psobsa_gbest_history, config[\"n_agents\"], f\"{psobsa_save_path}/{function_id}_num_evaluations.png\", log_scale=config[\"log_scale\"])\n",
    "                if neptune_logger:\n",
    "                    neptune_logger[f\"psobsa/{function_id}/individual\"].upload(f\"{psobsa_save_path}/{function_id}_individual.png\")\n",
    "                    neptune_logger[f\"psobsa/{function_id}/num_evaluations\"].upload(f\"{psobsa_save_path}/{function_id}_num_evaluations.png\")\n",
    "            except Exception as e:\n",
    "                import traceback; traceback.print_exc();    \n",
    "                print(f\"Function {function_id} failed with error {e}\")\n",
    "            successfull_functions.append(function_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Function {function_id} failed with error {e}\")\n",
    "        \n",
    "    df = analyze_results(save_dir, successfull_functions, function_selector, neptune_logger=neptune_logger)\n",
    "    if neptune_logger: \n",
    "        neptune_logger.stop()\n",
    "    return successfull_functions, save_dir, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_ids = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\"]\n",
    "config[\"n_agents\"] = 40\n",
    "config[\"n_dim\"] = 30\n",
    "config['objective_function'] = \"BenchmarkFunctions\" \n",
    "config[\"ep_length\"] = 100 \n",
    "config[\"log_scale\"] = True\n",
    "\n",
    "MODEL_PATH = \"training_results/experiment_101/policy-4800.pth\"\n",
    "env, agent_policy = initialize(config, mode=\"test\", model_path=MODEL_PATH)\n",
    "iters = 1\n",
    "save_dir = f\"new_test_results/{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}/\" \n",
    "title = \"experiment_103\"\n",
    "tags = \"testing with 40 agents and log scale\"\n",
    "neptune_logger = None #initialize_logger(api_token, title, config, mode=\"test\")\n",
    "successfull_functions, save_dir, df = run_test(function_ids, iters, save_dir, MODEL_PATH, config, neptune_logger=neptune_logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_results(save_dir, successfull_functions, function_selector, neptune_logger=neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load(\"/Users/elotech/Desktop/DeepHiveV2/notebooks/new_test_results/2024-03-04_17-55-16/pso/f01/f01_gbest_history.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_results(base_path, successfull_functions, function_selector, **kwargs):\n",
    "#     neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "#     # Define a multi-level column structure: each optimizer has the same sub-columns\n",
    "#     columns = pd.MultiIndex.from_product([['deephive', 'pso', 'psobsa'], \n",
    "#                                           [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]],\n",
    "#                                          names=['optimizer', 'metric'])\n",
    "#     # Initialize an empty DataFrame with these columns\n",
    "#     df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "#     for function_id in successfull_functions:\n",
    "#         row_data = {}\n",
    "#         function_info = function_selector.get_function(function_id)\n",
    "#         function_opt_val = function_info[\"global_min\"]\n",
    "        \n",
    "#         # Loop through each optimizer\n",
    "#         for optimizer in ['deephive', 'pso', 'psobsa']:\n",
    "#             data_path = base_path + f\"{optimizer}/{function_id}/{function_id}_gbest_history.npy\"\n",
    "#             try:\n",
    "#                 # Attempt to load the optimizer's result and compute metrics\n",
    "#                 gbest_values = np.load(data_path) * -1\n",
    "#                 mean_val, lower_val, upper_val = mean_confidence_interval(gbest_values)\n",
    "#                 error_val = abs(mean_val[-1] - function_opt_val)\n",
    "#                 row_data[(optimizer, 'mean')] = mean_val[-1]\n",
    "#                 row_data[(optimizer, 'lower')] = lower_val[-1]\n",
    "#                 row_data[(optimizer, 'upper')] = upper_val[-1]\n",
    "#                 row_data[(optimizer, 'optimum')] = function_opt_val\n",
    "#                 row_data[(optimizer, 'error')] = error_val\n",
    "                \n",
    "#                 # Additional logging or plotting can be added here as needed\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {optimizer} for function {function_id}: {e}\")\n",
    "#                 # Fill missing values if any error occurs\n",
    "#                 for metric in [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]:\n",
    "#                     row_data[(optimizer, metric)] = np.nan\n",
    "        \n",
    "#         # After collecting data for all optimizers, add the row to the DataFrame\n",
    "#         #df = df.append(pd.Series(row_data, name=function_id))\n",
    "#         df.loc[function_id] = row_data\n",
    "    \n",
    "#     # Save the DataFrame to CSV\n",
    "#     df.to_csv(f\"{base_path}/results.csv\")\n",
    "    \n",
    "#     # Log the DataFrame if Neptune logger is provided\n",
    "#     if neptune_logger:\n",
    "#         neptune_logger[\"test/results\"].upload(f\"{base_path}/results.csv\")\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = f\"new_test_results/2024-03-04_17-31-05/\" \n",
    "# analyze_results(save_dir, [\"f01\", \"f02\"], function_selector, neptune_logger=neptune_logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephive.environment.optimization_functions.benchmark_functions import FunctionSelector\n",
    "from deephive.environment.utils import mean_confidence_interval\n",
    "function_selector = FunctionSelector()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(base_path, model_lists, model_path_list, successful_functions, function_selector, **kwargs):\n",
    "    neptune_logger = kwargs.get(\"neptune_logger\", None)\n",
    "    # Define a multi-level column structure: each optimizer has the same sub-columns\n",
    "    columns = pd.MultiIndex.from_product([model_lists, \n",
    "                                          [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]],\n",
    "                                         names=['optimizer', 'metric'])\n",
    "    # Initialize an empty DataFrame with these columns\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for function_id in successful_functions:\n",
    "        row_data = {}\n",
    "        function_info = function_selector.get_function(function_id)\n",
    "        function_opt_val = function_info[\"global_min\"]\n",
    "        \n",
    "        # Loop through each optimizer\n",
    "        for optimizer, model_path in zip(model_lists, model_path_list):\n",
    "            data_path = model_path + f\"deephive/{function_id}/{function_id}_gbest_history.npy\"\n",
    "            try:\n",
    "                # Attempt to load the optimizer's result and compute metrics\n",
    "                gbest_values = np.load(data_path) * -1\n",
    "                mean_val, lower_val, upper_val = mean_confidence_interval(gbest_values)\n",
    "                error_val = abs(mean_val[-1] - function_opt_val)\n",
    "                row_data[(optimizer, 'mean')] = mean_val[-1]\n",
    "                row_data[(optimizer, 'lower')] = lower_val[-1]\n",
    "                row_data[(optimizer, 'upper')] = upper_val[-1]\n",
    "                row_data[(optimizer, 'optimum')] = function_opt_val\n",
    "                row_data[(optimizer, 'error')] = error_val\n",
    "                \n",
    "                # Additional logging or plotting can be added here as needed\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {optimizer} for function {function_id}: {e}\")\n",
    "                # Fill missing values if any error occurs\n",
    "                for metric in [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]:\n",
    "                    row_data[(optimizer, metric)] = np.nan\n",
    "        \n",
    "        # After collecting data for all optimizers, add the row to the DataFrame\n",
    "        #df = df.append(pd.Series(row_data, name=function_id))\n",
    "        df.loc[function_id] = row_data\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    df.to_csv(f\"{base_path}/results.csv\")\n",
    "    \n",
    "    # Log the DataFrame if Neptune logger is provided\n",
    "    if neptune_logger:\n",
    "        neptune_logger[\"test/results\"].upload(f\"{base_path}/results.csv\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_algo_path = \"other_algorithms/2024-03-10_10-38-15\"\n",
    "model_base_path = \"../new_test_results/2024-03-10_12-23-13\"\n",
    "\n",
    "columns = pd.MultiIndex.from_product([model_lists, \n",
    "                                          [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]],\n",
    "                                         names=['optimizer', 'metric'])\n",
    "# Initialize an empty DataFrame with these columns\n",
    "df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "function_ids = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\",\n",
    "                \"f20\", \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \"f31\", \"f32\", \"f33\", \"f34\", \"f35\", \"f36\", \"f37\", \"f38\", \"f39\", \"f40\",\n",
    "                \"f41\", \"f42\", \"f43\", \"f44\", \"f45\", \"f46\", \"f47\", \"f48\", \"f49\", \"f50\"]\n",
    "\n",
    "other_algos = [\"DE\", \"GA\", \"PSO\", \"SA\"]\n",
    "deephive_algos = [\"model102\", \"model103\", \"model104\"]\n",
    "model_lists = other_algos + deephive_algos\n",
    "\n",
    "for function_id in function_ids:\n",
    "    row_data = {}\n",
    "    function_info = function_selector.get_function(function_id)\n",
    "    function_opt_val = function_info[\"global_min\"]\n",
    "    for model in model_lists:\n",
    "        if model in other_algos:\n",
    "            model_path = f\"{other_algo_path}/{function_id}/{model}_histories.npy\"\n",
    "        else:\n",
    "            model_path = f\"{model_base_path}/{model}/deephive/{function_id}/{function_id}_gbest_history.npy\"\n",
    "            \n",
    "        print(model_path)\n",
    "        try:\n",
    "            # Attempt to load the optimizer's result and compute metrics\n",
    "            gbest_values = np.load(model_path) * -1 if model in deephive_algos else np.load(model_path)\n",
    "            mean_val, lower_val, upper_val = mean_confidence_interval(gbest_values)\n",
    "            error_val = abs(mean_val[-1] - function_opt_val)\n",
    "            row_data[(model, 'mean')] = mean_val[-1]\n",
    "            row_data[(model, 'lower')] = lower_val[-1]\n",
    "            row_data[(model, 'upper')] = upper_val[-1]\n",
    "            row_data[(model, 'optimum')] = function_opt_val\n",
    "            row_data[(model, 'error')] = error_val\n",
    "            \n",
    "            # Additional logging or plotting can be added here as needed\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model} for function {function_id}: {e}\")\n",
    "            # Fill missing values if any error occurs\n",
    "            for metric in [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]:\n",
    "                row_data[(model, metric)] = np.nan\n",
    "                \n",
    "        df.loc[function_id] = row_data\n",
    "        \n",
    "df.to_excel(\"results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_algo_path = \"other_algorithms/2024-03-10_10-38-15\"\n",
    "model_base_path = \"../new_test_results/2024-03-10_12-23-13\"\n",
    "save_dir = \"optimization_results/\"\n",
    "\n",
    "columns = pd.MultiIndex.from_product([model_lists, \n",
    "                                          [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]],\n",
    "                                         names=['optimizer', 'metric'])\n",
    "# Initialize an empty DataFrame with these columns\n",
    "df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "function_ids = [\"f01\", \"f02\", \"f03\", \"f04\", \"f05\", \"f06\", \"f07\", \"f08\", \"f09\", \"f10\", \"f11\", \"f12\", \"f13\", \"f14\", \"f15\", \"f16\", \"f17\", \"f18\", \"f19\",\n",
    "                \"f20\", \"f21\", \"f22\", \"f23\", \"f24\", \"f25\", \"f26\", \"f27\", \"f28\", \"f29\", \"f30\", \"f31\", \"f32\", \"f33\", \"f34\", \"f35\", \"f36\", \"f37\", \"f38\", \"f39\", \"f40\",\n",
    "                \"f41\", \"f42\", \"f43\", \"f44\", \"f45\", \"f46\", \"f47\", \"f48\", \"f49\", \"f50\"]\n",
    "\n",
    "other_algos = [\"DE\", \"GA\", \"PSO\", \"SA\"]\n",
    "deephive_algos = [\"model102\", \"model103\", \"model104\"]\n",
    "model_lists = other_algos + deephive_algos\n",
    "\n",
    "for function_id in function_ids:\n",
    "    row_data = {}\n",
    "    function_info = function_selector.get_function(function_id)\n",
    "    function_opt_val = function_info[\"global_min\"]\n",
    "    for model in model_lists:\n",
    "        if model in other_algos:\n",
    "            model_path = f\"{other_algo_path}/{function_id}/{model}_histories.npy\"\n",
    "        else:\n",
    "            model_path = f\"{model_base_path}/{model}/deephive/{function_id}/{function_id}_gbest_history.npy\"\n",
    "            \n",
    "        print(model_path)\n",
    "        try:\n",
    "            # Attempt to load the optimizer's result and compute metrics\n",
    "            gbest_values = np.load(model_path) * -1 if model in deephive_algos else np.load(model_path)\n",
    "            mean_val, lower_val, upper_val = mean_confidence_interval(gbest_values)\n",
    "            error_val = abs(mean_val[-1] - function_opt_val)\n",
    "            row_data[(model, 'mean')] = mean_val[-1]\n",
    "            row_data[(model, 'lower')] = lower_val[-1]\n",
    "            row_data[(model, 'upper')] = upper_val[-1]\n",
    "            row_data[(model, 'optimum')] = function_opt_val\n",
    "            row_data[(model, 'error')] = error_val\n",
    "            \n",
    "            # Additional logging or plotting can be added here as needed\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model} for function {function_id}: {e}\")\n",
    "            # Fill missing values if any error occurs\n",
    "            for metric in [\"mean\", \"lower\", \"upper\", \"optimum\", \"error\"]:\n",
    "                row_data[(model, metric)] = np.nan\n",
    "                \n",
    "        df.loc[function_id] = row_data\n",
    "        \n",
    "df.to_excel(f\"{save_dir}/results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define your paths, lists, and function IDs as before...\n",
    "other_algo_path = \"other_algorithms/2024-03-10_10-38-15\"\n",
    "model_base_path = \"../new_test_results/2024-03-10_12-23-13\"\n",
    "save_dir = \"optimization_results/\"\n",
    "other_algos = [\"DE\", \"GA\", \"PSO\", \"SA\"]\n",
    "deephive_algos = [\"model102\", \"model103\", \"model104\"]\n",
    "model_lists = other_algos + deephive_algos\n",
    "function_ids = [f\"f0{i}\" if i < 10 else f\"f{i}\" for i in range(1, 51)]\n",
    "\n",
    "for function_id in function_ids[:]:\n",
    "    # Temporarily load one file to determine the maximum number of iterations\n",
    "    sample_model_path = os.path.join(other_algo_path, f\"{function_ids[0]}/{other_algos[0]}_histories.npy\")\n",
    "    sample_data = np.load(sample_model_path)\n",
    "    max_iterations = 1010  # Default value for the sample data\n",
    "\n",
    "    # Create column names for each iteration and metric\n",
    "    columns = []\n",
    "    for model in model_lists:\n",
    "        for metric in [\"mean\", \"lowest\"]:\n",
    "            columns.extend([f\"{model}_{metric}\"])\n",
    "\n",
    "    # Initialize the DataFrame for this function with dynamic columns\n",
    "    df = pd.DataFrame(columns=columns)  # Single row to populate\n",
    "\n",
    "    for model in model_lists:\n",
    "        try:\n",
    "            if model in other_algos:\n",
    "                model_path = os.path.join(other_algo_path, f\"{function_id}/{model}_histories.npy\")\n",
    "            else:\n",
    "                model_path = os.path.join(model_base_path, f\"{model}/deephive/{function_id}/{function_id}_gbest_history.npy\")\n",
    "\n",
    "            gbest_values = np.load(model_path)\n",
    "            if model in deephive_algos:\n",
    "                gbest_values *= -1  \n",
    "            \n",
    "            if gbest_values.shape[1] > max_iterations:\n",
    "                max_iterations = gbest_values.shape[1]\n",
    "                \n",
    "            # Calculate the mean and lowest values for each iteration\n",
    "            mean_vals, lowest_vals, _ = mean_confidence_interval(gbest_values)\n",
    "            # Pad the arrays to the maximum number of iterations\n",
    "            mean_vals = np.pad(mean_vals, (0, max_iterations - len(mean_vals)), constant_values=np.nan)\n",
    "            lowest_vals = np.pad(lowest_vals, (0, max_iterations - len(lowest_vals)), constant_values=np.nan)\n",
    "            \n",
    "            df[f\"{model}_mean\"] = mean_vals\n",
    "            df[f\"{model}_lowest\"] = lowest_vals\n",
    "            \n",
    "        except Exception as e:\n",
    "            #import traceback; traceback.print_exc();\n",
    "            print(f\"Error processing {model} for function {function_id}: {e}\")\n",
    "\n",
    "    # Ensure the save directory exists and save the DataFrame as a CSV\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    df.to_excel(os.path.join(save_dir, f\"{function_id}_results.xlsx\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SA\"\n",
    "function_id = \"f01\"\n",
    "model_path = os.path.join(other_algo_path, f\"{function_id}/{model}_histories.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbest_values = np.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 58)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbest_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea, low, upp = mean_confidence_interval(gbest_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.50531703, 11.50531703, 11.50531703, 11.50531703, 11.50531703,\n",
       "       11.50531703, 11.50531703, 11.50531703, 11.50531703, 11.50531703,\n",
       "       11.50531703, 11.50531703, 11.50531703, 11.50531703, 11.50531703,\n",
       "       11.50531703, 11.50531703, 11.50531703, 11.50531703, 11.50531703,\n",
       "       11.50531703, 11.50531703, 11.50531703, 11.50531703, 11.3209817 ,\n",
       "       11.3209817 , 11.28079852, 11.28079852, 11.28079852, 11.28079852,\n",
       "       11.28079852, 11.207999  , 11.08512319, 10.85370496, 10.81490854,\n",
       "       10.58790761, 10.42064126, 10.35445952, 10.18244036, 10.09318225,\n",
       "        9.88690437,  9.26643107,  8.8196819 ,  8.27402997,  7.68276629,\n",
       "        7.26937584,  7.00477172,  6.6451879 ,  6.18398699,  5.78734571,\n",
       "        5.18046689,  4.62893227,  4.43066991,  4.15174814,  3.65021795,\n",
       "        3.42069952,  3.07788575,  2.90676415])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
