{
    "env_name": "OptimizationEnv",
    "n_agents": 10,
    "n_dim": 2,
    "ep_length": 20,
    "init_state": null,
    "opt_bound": 0.9,
    "reward_type": "full",
    "freeze": true,
    "observation_scheme": "DefaultObservationScheme",
    "reward_scheme": "FullRewardScheme",
    "objective_function":  "GaussianPeakFunction",
    "optimization_type": "maximize",
    "use_gbest": true,
    "use_optimal_value": false,
    "update_timestep": 20,
    "log_interval": 100,
    "enforce_good_actions": false,
    "use_surrogate": false,
    "role_std":{"explorer": 0.5, "exploiter": 0.5},
    "lr": 0.0001,
    "lr_decay": 0.0,
    "beta": 0.9,
    "gamma": 0.99,
    "K_epochs":32,
    "eps_clip": 0.2,
    "action_std": 0.02,
    "action_dim": 1,
    "obs_dim": 9,
    "layer_size":[16, 16],
    "std_min": 0.02,
    "std_max": 0.3,
    "test_action_std": 0.02,
    "std_type": "linear_decay",
    "variable_std": false,
    "pretrained": false,
    "ckpt_folder": "checkpoints",
    "initialization": "xavier_normal",
    "decay_rate":0.9,
    "decay_interval": 1000,
    "save_interval": 2500,
    "min_action_std": 0.02,
    "n_episodes":2000,
    "grid_resolution":0.1,

    "pso_omega": 0.5,
    "pso_phip": 2,
    "pso_phig": 2,
    "pso_minimize": false,
    "pso_normalize": true,
    "pso_use_net" : false,
    "pso_minfunc": 1e-8,
    "pso_minstep": 1e-8


}




