{
    "env_name": "OptimizationEnv",
    "n_agents": 10,
    "n_dim": 2,
    "ep_length": 20,
    "init_state": null,
    "opt_bound": 0.9,
    "reward_type": "full",
    "freeze": true,
    "observation_scheme": "DefaultObservationScheme",
    "reward_scheme": "FullRewardScheme",
    "objective_function":  "GaussianPeakFunction",
    "optimization_type": "maximize",
    "use_gbest": false,
    "use_optimal_value": true,
    "update_timestep": 20,
    "log_interval": 100,
    "use_surrogate": false,
    "role_std":{"explorer": 0.2, "exploiter": 0.2},

    "lr": 0.0001,
    "lr_decay": 0.0,
    "beta": 0.9,
    "gamma": 0.99,
    "K_epochs":32,
    "eps_clip": 0.2,
    "action_std": 0.5,
    "action_dim": 1,
    "obs_dim": 9,
    "layer_size":[16, 16],
    "std_min": 0.03,
    "std_max": 0.5,
    "test_action_std": 0.05,
    "learn_std": false,
    "pretrained": false,
    "ckpt_folder": "checkpoints",
    "initialization": "xavier_normal",
    "decay_rate":0.9,
    "decay_interval": 500,
    "save_interval": 2500,
    "min_action_std": 0.02,
    "n_episodes":1000,


    "pso_omega": 0.5,
    "pso_phip": 2,
    "pso_phig": 2,
    "pso_minimize": false,
    "pso_normalize": true,
    "pso_use_net" : false,
    "pso_minfunc": 1e-8,
    "pso_minstep": 1e-8


}




