{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from policies.mappo import MAPPO\n",
    "from environment.optimization_environment import OptimizationEnv\n",
    "from environment.utils import parse_config\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import neptune\n",
    "from neptune.types import File\n",
    "import argparse \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "from other_algorithms.pso import ParticleSwarmOptimizer\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(config_path, mode=\"train\", **kwargs):\n",
    "    env = OptimizationEnv(config_path)\n",
    "    agent_policy = MAPPO(config_path)\n",
    "    if mode == \"test\" or mode == \"benchmark\":\n",
    "        model_path = kwargs.get(\"model_path\", None)\n",
    "        if model_path is None:\n",
    "            raise ValueError(\"Model path must be provided for testing\")\n",
    "        agent_policy.load(model_path)\n",
    "    return env, agent_policy\n",
    "\n",
    "def print_items(**kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(key, value)\n",
    "        \n",
    "def get_action(observation_info, agent_policy, env):\n",
    "    observation, observation_std = observation_info\n",
    "    actions = np.zeros((env.n_agents, env.n_dim))\n",
    "    for dim in range(env.n_dim):\n",
    "        observation[dim] = observation[dim].astype(np.float32)\n",
    "        #print(observation[dim])\n",
    "        observation_std[dim] = observation_std[dim].astype(np.float32)\n",
    "        action = agent_policy.select_action(observation[dim], observation_std[dim])\n",
    "        actions[:, dim] = action\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/config.json'\n",
    "model_path = \"training_runs/2023-11-03_08-25-56/policy-30000.pth\"\n",
    "mode = \"test\"\n",
    "env, agent_policy = initialize(config_path, mode=mode, model_path=model_path)\n",
    "config = parse_config(config_path)\n",
    "agent_policy.set_action_std(config[\"test_action_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_info = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = get_action(observation_info, agent_policy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_info, reward, done, info = env.step(actions)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class ExplorationModule:\n",
    "    def __init__(self, initial_samples, n_components=1, max_samples=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the exploration module with a Gaussian Mixture Model.\n",
    "\n",
    "        Parameters:\n",
    "        - initial_samples: An array of initial sample points.\n",
    "        - n_components: Number of components (Gaussians) in the initial GMM.\n",
    "        - max_samples: Maximum number of samples to use for updating the GMM.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.max_samples = max_samples\n",
    "        self.samples = initial_samples\n",
    "        self.gmm = GaussianMixture(n_components=self.n_components)\n",
    "        self.gmm.fit(self.samples)\n",
    "        self.upper_bound = kwargs.get(\"upper_bound\", 1)\n",
    "        self.lower_bound = kwargs.get(\"lower_bound\", -1)\n",
    "    \n",
    "    def update_distribution(self, new_samples):\n",
    "        \"\"\"\n",
    "        Update the GMM with new samples.\n",
    "\n",
    "        Parameters:\n",
    "        - new_samples: An array of new sample points.\n",
    "        \"\"\"\n",
    "        # Optionally limit the number of samples to prevent excessive growth\n",
    "        if self.max_samples and len(self.samples) >= self.max_samples:\n",
    "            self.samples = self.samples[-self.max_samples:]\n",
    "        \n",
    "        self.samples = np.vstack([self.samples, new_samples])\n",
    "        self.gmm = GaussianMixture(n_components=self.n_components)\n",
    "        self.gmm.fit(self.samples)\n",
    "\n",
    "    def sample_candidate_points(self, n_samples):\n",
    "        \"\"\"\n",
    "        Generate new candidate points based on the current GMM.\n",
    "\n",
    "        Parameters:\n",
    "        - n_samples: Number of candidate points to generate.\n",
    "        \"\"\"\n",
    "        return self.gmm.sample(n_samples)[0]\n",
    "\n",
    "    def assess_novelty(self, points):\n",
    "        \"\"\"\n",
    "        Assess the novelty of given points based on the current GMM.\n",
    "\n",
    "        Parameters:\n",
    "        - points: An array of points to assess.\n",
    "        \"\"\"\n",
    "        # Evaluate the probability density of each point under each GMM component\n",
    "        densities = np.array([multivariate_normal(mean=mean, cov=cov, allow_singular=True).pdf(points)\n",
    "                              for mean, cov in zip(self.gmm.means_, self.gmm.covariances_)])\n",
    "\n",
    "        # Novelty score could be the inverse of density or a more complex function\n",
    "        novelty_scores = 1 / np.max(densities, axis=0)\n",
    "        return novelty_scores\n",
    "\n",
    "    def get_variance(self, point):\n",
    "        \"\"\"\n",
    "        Estimate the variance of a given point based on the GMM.\n",
    "\n",
    "        Parameters:\n",
    "        - point: The point to estimate variance for.\n",
    "        \"\"\"\n",
    "        # Find the nearest GMM component to the point\n",
    "        nearest_component = np.argmin(np.linalg.norm(self.gmm.means_ - point, axis=1))\n",
    "        # Return the variance (diagonal of the covariance matrix) of the nearest component\n",
    "        return np.diag(self.gmm.covariances_[nearest_component])\n",
    "\n",
    "    def plot_distribution(self):\n",
    "        \"\"\"\n",
    "        Plot the current GMM.\n",
    "        \"\"\"\n",
    "        # Create a mesh grid on which to evaluate the GMM\n",
    "        x = np.linspace(self.lower_bound, self.upper_bound, 100)\n",
    "        y = np.linspace(self.lower_bound, self.upper_bound, 100)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        XY = np.array([X.ravel(), Y.ravel()]).T\n",
    "\n",
    "        # Evaluate the GMM's probability density function (PDF) on the grid\n",
    "        Z = np.exp(self.gmm.score_samples(XY))\n",
    "        Z = Z.reshape(X.shape)\n",
    "        # Plot the contour\n",
    "        plt.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.title('GMM Contour Plot')\n",
    "        plt.xlabel('X-axis')\n",
    "        plt.ylabel('Y-axis')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "particle_data = env._get_actual_state()[:, :-1]\n",
    "print(particle_data)\n",
    "gmm = ExplorationModule(initial_samples=env._get_actual_state()[:, :-1], n_components=1, max_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_point = gmm.sample_candidate_points(10)\n",
    "print(candidate_point)\n",
    "novelty_scores = gmm.assess_novelty(candidate_point)\n",
    "print(novelty_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the particles and candidate points in 2D with different colors let the size of the points be the novelty score\n",
    "# plot the distribution of the particles and candidate points in 2D with different colors let the size of the points be the novelty score\n",
    "plt.rcParams['figure.figsize'] = [7, 7]\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "plt.rcParams['font.size'] = 12\n",
    "# def plot_2d_distribution(particles, candidate_points, novelty_scores):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     x = np.linspace(env.bounds[0], env.bounds[1], 1000)\n",
    "#     y = np.linspace(env.bounds[0], env.bounds[1], 1000)\n",
    "#     X, Y = np.meshgrid(x, y)\n",
    "#     Z = env.objective_function.evaluate(np.array([X.flatten(), Y.flatten()]).T).reshape(X.shape)\n",
    "#     ax.contour(X, Y, Z, 50)\n",
    "#     ax.set_xlim(env.bounds[0][0], env.bounds[1][0])\n",
    "#     ax.set_ylim(env.bounds[0][1], env.bounds[1][1])\n",
    "#     ax.scatter(particles[:, 0], particles[:, 1], c='blue', label='Particles')\n",
    "#     # scale the novelty scores to be between 1 and 10\n",
    "#     novelty_scores = (novelty_scores - np.min(novelty_scores)) / (np.max(novelty_scores) - np.min(novelty_scores)) * 9 + 1\n",
    "#     ax.scatter(candidate_points[:, 0], candidate_points[:, 1], c='red', label='Candidate points', s=novelty_scores*100)\n",
    "#     ax.legend()\n",
    "#     plt.show()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def plot_2d_distribution(particles, candidate_points, novelty_scores, gmm, env):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.linspace(env.bounds[0], env.bounds[1], 1000)\n",
    "    y = np.linspace(env.bounds[0], env.bounds[1], 1000)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = env.objective_function.evaluate(np.array([X.flatten(), Y.flatten()]).T).reshape(X.shape)\n",
    "\n",
    "    # Evaluate the GMM PDF on the grid\n",
    "    XY = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    Z_gmm = np.exp(gmm.gmm.score_samples(XY)).reshape(X.shape)\n",
    "    \n",
    "    # Plot the objective function contour\n",
    "    ax.contour(X, Y, Z, 50)\n",
    "    \n",
    "    # Plot the GMM contour with some transparency\n",
    "    ax.contourf(X, Y, Z_gmm, 50, cmap='viridis', alpha=0.5)  # Set alpha for transparency\n",
    "\n",
    "    ax.set_xlim(env.bounds[0][0], env.bounds[1][0])\n",
    "    ax.set_ylim(env.bounds[0][1], env.bounds[1][1])\n",
    "\n",
    "    # Plot particles and candidate points with scaled novelty scores\n",
    "    ax.scatter(particles[:, 0], particles[:, 1], c='blue', label='Particles')\n",
    "    novelty_scores = (novelty_scores - np.min(novelty_scores)) / (np.max(novelty_scores) - np.min(novelty_scores)) * 9 + 1\n",
    "    ax.scatter(candidate_points[:, 0], candidate_points[:, 1], c='red', label='Candidate points', s=novelty_scores*100)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_2d_distribution(particle_data, candidate_point, novelty_scores, gmm, env)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config/config.json'\n",
    "model_path = \"training_runs/2023-11-03_08-25-56/policy-30000.pth\"\n",
    "mode = \"test\"\n",
    "env, agent_policy = initialize(config_path, mode=mode, model_path=model_path)\n",
    "config = parse_config(config_path)\n",
    "agent_policy.set_action_std(config[\"test_action_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters  = 10\n",
    "obs = env.reset()\n",
    "particle_data = env._get_actual_state()[:, :-1]\n",
    "# print(particle_data)\n",
    "gmm = ExplorationModule(initial_samples=particle_data, n_components=2, max_samples=1000)\n",
    "for i in range(iters):\n",
    "    particle_data = env._get_actual_state()[:, :-1]\n",
    "    actions = get_action(obs, agent_policy, env)\n",
    "    obs, reward, done, info = env.step(actions)\n",
    "    gmm.update_distribution(particle_data)\n",
    "    candidate_point = env._get_actual_state()[:, :-1]\n",
    "    novelty_scores = gmm.assess_novelty(candidate_point)\n",
    "    print(novelty_scores)\n",
    "    plot_2d_distribution(particle_data, candidate_point, novelty_scores, gmm, env)\n",
    "    gmm.plot_distribution()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters  = 20\n",
    "obs = env.reset()\n",
    "particle_data = env._get_actual_state()[:, :-1]\n",
    "# print(particle_data)\n",
    "gmm = ExplorationModule(initial_samples=particle_data, n_components=2, max_samples=1000)\n",
    "for i in range(iters):\n",
    "    particle_data = env._get_actual_state()[:, :-1]\n",
    "    actions = get_action(obs, agent_policy, env)\n",
    "    obs, reward, done, info = env.step(actions)\n",
    "    gmm.update_distribution(particle_data)\n",
    "    candidate_point = env._get_actual_state()[:, :-1]\n",
    "    novelty_scores = gmm.assess_n0ovelty(candidate_point)\n",
    "    print(novelty_scores)\n",
    "    plot_2d_distribution(particle_data, candidate_point, novelty_scores, gmm, env)\n",
    "    gmm.plot_distribution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "        a = 1.0 * np.array(data)\n",
    "        n = len(a)\n",
    "        m, se = np.mean(a, axis = 0), scipy.stats.sem(a)\n",
    "        h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "        return m, m-h, m+h\n",
    "\n",
    "def num_function_evaluation(fopt, n_agents, save_dir, opt_value, label=\"TEST OPT\"):\n",
    "    # convert fopt to numpy array if it is not already\n",
    "        fopt = np.array(fopt)\n",
    "        mf1 = np.mean(fopt, axis = 0)\n",
    "        err = np.std(fopt, axis = 0)\n",
    "        mf1, ml1, mh1 = mean_confidence_interval(fopt,0.95)\n",
    "\n",
    "        fig = plt.figure(figsize=(6,4), dpi=200)\n",
    "        plt.rcParams[\"figure.figsize\"] = [6, 4]\n",
    "        plt.rcParams[\"figure.autolayout\"] = True\n",
    "        plt.fill_between((np.arange(len(mf1))+1)*n_agents, ml1, mh1, alpha=0.1, edgecolor='#3F7F4C', facecolor='#7EFF99')\n",
    "        plt.plot((np.arange(len(mf1))+1)*n_agents, mf1, linewidth=2.0, label = label, color='#3F7F4C')\n",
    "        if opt_value is not None:\n",
    "            plt.plot((np.arange(len(mf1))+1)*n_agents, np.ones(len(mf1))*opt_value, linewidth=1.0, label = 'True OPT', color='#CC4F1B')\n",
    "\n",
    "        plt.xlabel('number of function evaluations', fontsize = 14)\n",
    "        plt.ylabel('best fitness value', fontsize = 14)\n",
    "\n",
    "        plt.legend(fontsize = 14, frameon=False)\n",
    "        plt.xscale('log')\n",
    "        plt.yticks(fontsize = 14)\n",
    "        plt.savefig(save_dir)\n",
    "        # close the figure\n",
    "        plt.close(fig)\n",
    "\n",
    "def plot_num_function_evaluation(fopt, n_agents, save_dir, opt_value, show_std=False, symbol_list=None, color_list=None, label_list=None, show=True, title=None):\n",
    "        # The method implementation goes here\n",
    "        fig = plt.figure(figsize=(6, 4), dpi=200)\n",
    "        plt.rcParams[\"figure.figsize\"] = [6, 4]\n",
    "        plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "        if symbol_list is None:\n",
    "            symbol_list = ['-']\n",
    "        if color_list is None:\n",
    "            color_list = ['#3F7F4C']\n",
    "        if label_list is None:\n",
    "            label_list = ['DeepHive']\n",
    "\n",
    "        print(f\"Number of function evaluations: {len(fopt[0])}\")\n",
    "        print(f\"Number of algorithms: {len(fopt)}\")\n",
    "\n",
    "        if len(fopt) == 1:\n",
    "            print(\"Single algorithm\")\n",
    "            num_function_evaluation(fopt[0], n_agents, save_dir, opt_value, label=label_list[0])\n",
    "        else:\n",
    "            for i in range(len(fopt)):\n",
    "                \n",
    "                mf1, ml1, mh1 = mean_confidence_interval(fopt[i], 0.95)\n",
    "                if show_std:\n",
    "                    plt.errorbar((np.arange(len(mf1)) + 1) * n_agents, mf1, yerr=mh1 - ml1, linewidth=2.0,\n",
    "                                label=label_list[i],\n",
    "                                color=color_list[i])\n",
    "                # plt.fill_between((np.arange(len(mf1)) + 1) * n_agents, ml1, mh1, alpha=0.1, edgecolor='#3F7F4C',\n",
    "                #                  facecolor=color_list[i])\n",
    "                plt.plot((np.arange(len(mf1)) + 1) * n_agents, mf1, symbol_list[i], linewidth=1, label=label_list[i],\n",
    "                        color=color_list[i])\n",
    "\n",
    "        if opt_value is not None:\n",
    "            plt.plot((np.arange(len(mf1))+1)*n_agents, np.ones(len(mf1))*opt_value, linewidth=0.5, label = 'True OPT', color='#CC4F1B')\n",
    "\n",
    "        plt.xlabel('number of function evaluations', fontsize=14)\n",
    "        plt.ylabel('best fitness value', fontsize=14)\n",
    "        plt.legend(fontsize=8, frameon=False, loc=\"lower right\")\n",
    "        plt.xscale('log')\n",
    "        plt.yticks(fontsize=14)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        if show:\n",
    "            plt.show()\n",
    "    \n",
    "        plt.savefig(save_dir)\n",
    "        #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1_dir = \"benchmarking_runs/2023-11-13_10-31-46\"  # std = 0.05\n",
    "opt2_dir = \"benchmarking_runs/2023-11-13_10-34-03\" # std = 0.02\n",
    "opt3_dir = \"benchmarking_runs/2023-11-13_10-35-39\" # std = 0.035\n",
    "opt4_dir = \"benchmarking_runs/2023-11-13_10-37-39\" # learn_std - 0.3 - 0.03\n",
    "opt5_dir = \"benchmarking_runs/2023-11-13_10-39-21\" # learn_std - 0.5 - 0.005\n",
    "opt6_dir = \"benchmarking_runs/2023-11-13_10-40-59\" # unfreeze learn_std - 0.4 - 0.02\n",
    "\n",
    "opt_dirs = [opt1_dir, opt2_dir, opt3_dir, opt4_dir, opt5_dir, opt6_dir]\n",
    "labels = [\"std-0.05\", \"std-0.02\", \"std-0.035\", \"ls-0.3-0.03\", \"ls-0.5-0.005\", \"unfreeze-ls-0.4-0.02\"]\n",
    "colors = [\"red\", \"green\", \"blue\", \"orange\", \"purple\", \"brown\"]\n",
    "symbols = [\"-\", \"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "\n",
    "def prepare_opt_values(dir):\n",
    "    # get all the .npy files in the directory\n",
    "    opt_values = []\n",
    "    files = os.listdir(dir)\n",
    "    files = [file for file in files if file.endswith(\".npy\")]\n",
    "    for file in files:\n",
    "        opt_value = np.load(os.path.join(dir, file))\n",
    "        # grab all the columns except the last one\n",
    "        opt_value = opt_value[:, -1]\n",
    "        #print(opt_value)\n",
    "        opt_values.append(opt_value.tolist())\n",
    "    return opt_values\n",
    "\n",
    "ploting_values = []\n",
    "for dir in opt_dirs:\n",
    "    opt_values = prepare_opt_values(dir)\n",
    "    ploting_values.append(opt_values)\n",
    "\n",
    "plot_num_function_evaluation(ploting_values, 10, \"benchmarking_runs/plot.png\", 0.2, label_list=labels, show_std=False, color_list=colors, symbol_list=symbols, show=False, title=\"2D cosine mixture function benchmarking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1_dir = \"benchmarking_runs/2023-11-13_10-57-38\"  # std = 0.05\n",
    "opt2_dir = \"benchmarking_runs/2023-11-13_10-56-41\" # std = 0.02\n",
    "opt3_dir = \"benchmarking_runs/2023-11-13_10-55-41\" # std = 0.035\n",
    "opt4_dir = \"benchmarking_runs/2023-11-13_10-54-53\" # learn_std - 0.3 - 0.03\n",
    "opt5_dir = \"benchmarking_runs/2023-11-13_10-53-53\" # learn_std - 0.5 - 0.005\n",
    "opt6_dir = \"benchmarking_runs/2023-11-13_10-52-32\" # unfreeze learn_std - 0.5 - 0.05\n",
    "\n",
    "opt_dirs = [opt1_dir, opt2_dir, opt3_dir, opt4_dir, opt5_dir, opt6_dir]\n",
    "labels = [\"std-0.05\", \"std-0.02\", \"std-0.035\", \"ls-0.3-0.03\", \"ls-0.5-0.005\", \"unfreeze-ls-0.4-0.02\"]\n",
    "colors = [\"red\", \"green\", \"blue\", \"orange\", \"purple\", \"brown\"]\n",
    "symbols = [\"-\", \"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "\n",
    "def prepare_opt_values(dir):\n",
    "    # get all the .npy files in the directory\n",
    "    opt_values = []\n",
    "    files = os.listdir(dir)\n",
    "    files = [file for file in files if file.endswith(\".npy\")]\n",
    "    for file in files:\n",
    "        opt_value = np.load(os.path.join(dir, file))\n",
    "        # grab all the columns except the last one\n",
    "        opt_value = opt_value[:, -1]\n",
    "        #print(opt_value)\n",
    "        opt_values.append(opt_value.tolist())\n",
    "    return opt_values\n",
    "\n",
    "ploting_values = []\n",
    "for dir in opt_dirs:\n",
    "    opt_values = prepare_opt_values(dir)\n",
    "    ploting_values.append(opt_values)\n",
    "\n",
    "plot_num_function_evaluation(ploting_values, 10, \"benchmarking_runs/plot1.png\", 0.2, label_list=labels, show_std=False, color_list=colors, symbol_list=symbols, show=False, title=\"3D cosine mixture function benchmarking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_function_evaluation([opt_values_1, opt_values_2], 1, \"test.png\", 0.2, show_std=False, symbol_list=['-', '--'], color_list=['#3F7F4C', '#CC4F1B'], label_list=['DeepHive', 'PSO'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eloEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
